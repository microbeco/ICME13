% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={ICME 13 - Rome Edition},
  pdfauthor={Manuela Coci; Luigi Gallucci; Davide Corso},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{ICME 13 - Rome Edition}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Crash course on Nanopore sequencing for microbial ecology}
\author{Manuela Coci \and Luigi Gallucci \and Davide Corso}
\date{Last update: 2024-03-13}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter{Introduction}\label{introduction}

MicrobEco is a non-profit scientific organization dedicated to the advancement of scientific research and know-how in the field of microbiology and ecology. MICROBECO's mission is to promote the understanding and appreciation of microbes, to disseminate knowledge, strengthen collaboration, create and provide opportunities to learn about, discuss and challenge frontier issues in microbial ecology and to support the development of new technologies and applications that can benefit society. We connect scientists and we educate future generations to know and to do not fear microbes.

\section{ICME 13 - Rome}\label{icme-13---rome}

The course ``Crash course on Nanopore sequencing for microbial ecology'' corresponds to the 13th edition of the ICME- International course in microbial ecology, which annually gathers selected students to receive theoretical and practical training on one or more techniques in microbial ecology. From 11 to 14 March 2024, 25 PhD students and early career researchers will have practical experience in sequencing using Nanopore technology (MinIon) and performing bioinformatic analysis of Nanopore sequencing data. As in the tradition of ICME, The entire course is designed to bring together beginners and experts, and to create a strong collaboration between colleagues that extends beyond the days of the course.

The course is held at the laboratory of CNR-IRSA Institute of Water Research Roma Montelibretti.

Official page: \url{https://www.microbeco.org/icme13-roma-2024/}

\chapter{Introduction to the command line}\label{introduction-to-the-command-line}

\section{Set-up a terminal}\label{set-up-a-terminal}

\textbf{MacOS/Linux:} Launch terminal on your machine.

\textbf{Windows users options:}
\textbf{Windows Subsystem for Linux (WSL)} --\textgreater{} It creates an Ubuntu terminal environment where you can code just like from a linux Ubuntu terminal. This is useful for the course as well as for practice working in bash. \href{https://ubuntu.com/wsl}{from ubuntu website} and \href{https://learn.microsoft.com/en-us/windows/wsl/install}{from the windows website}

\textbf{SSH client} --\textgreater{} Windows: {[}MobaXterm{]}(~\url{https://mobaxterm.mobatek.net/download-home-edition.html} . This is a very basic ssh client, meaning, it will allow you to connect to the server and it will serve as a terminal for the course.

If you are already using Visual Studio, it needs one ssh~\href{https://code.visualstudio.com/docs/remote/ssh}{extension}~plugin to serve as a ssh.

\textbf{Git for windows} --\textgreater{} I am not sure this can be used as a ssh but, in regards to this course, it is also useful to practice coding on the terminal.

Very last-minute resource --\textgreater{} launch \href{https://bellard.org/jslinux/vm.html?url=alpine-x86.cfg&mem=192}{this terminal emulator} in a new window.

\section{Working with the command line}\label{working-with-the-command-line}

Most of the activities of the bioinformatic section of this workshop will be done using the Unix command line (Unix shell).\\
It is therefore highly recommended to have at least a basic grasp of how to get around in the Unix shell.\\
We will now dedicate one hour or so to follow some basic to learn (or refresh) the basics of the Unix shell.

\begin{quote}
{[}!question{]} What is the UNIX SHELL? What is Bash?

\begin{quote}
{[}!todo{]} The shell is a program that enables us to send commands to the computer and receive output. It is also referred to as the terminal or command line. Some computers include a default Unix Shell program.
\end{quote}

\begin{quote}
{[}!todo{]} The most popular Unix shell is Bash, Bash is a shell and a command language.
\end{quote}

For a \textbf{Mac} computer running macOS Mojave or earlier releases, the default Unix Shell is Bash.

For a \textbf{Mac} computer running macOS Catalina or later releases, the default Unix Shell is Zsh. Your default shell is available via the Terminal program within your Utilities folder.

The default Unix Shell for \textbf{Linux} operating systems is usually Bash.
\end{quote}

\section{Playing around with basic UNIX commands}\label{playing-around-with-basic-unix-commands}

\subsection{Some notes!}\label{some-notes}

These commands:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mkdir}\NormalTok{ unix\_shell}
\BuiltInTok{cd}\NormalTok{ unix\_shell}
\end{Highlighting}
\end{Shaded}

\ldots are commands you need to type in the shell.
Each line is a command.
Commands have to be typed in a single line, one at a time.
After each command, hit ``Enter'' to execute it.

Things starting with a hashtag:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This is a comment and is ignored by the shell}
\end{Highlighting}
\end{Shaded}

\ldots are comments embedded in the code to give instructions to the user.
Anything in a line starting with a \texttt{\#} is ignored by the shell.

Different commands might expect different syntaxes and different types of arguments. Some times the order matters, some times it doesn't! The best way to check how to run a command is by taking a look at its manual with the command \texttt{man} or to the --help for a shorter version of it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{man}\NormalTok{ mkdir}

\CommentTok{\# You can scroll down by hitting the space bar}
\CommentTok{\# To quit, hit "q"}

\FunctionTok{mkdir} \AttributeTok{{-}h}

\CommentTok{\# did it work?}
\end{Highlighting}
\end{Shaded}

\subsection{Creating and navigating directories}\label{creating-and-navigating-directories}

First let's see where we are:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{pwd}  \CommentTok{\# print working directory}
\end{Highlighting}
\end{Shaded}

Are there any files here? Let's list the contents of the folder:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ls}

\CommentTok{\# or }

\ExtensionTok{ll}
\end{Highlighting}
\end{Shaded}

Let's now create a new folder called \texttt{unix\_shell}. In addition to the command (\texttt{mkdir}), we are now passing a term (also known as an argument) which, in this case, is the name of the folder we want to create:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mkdir}\NormalTok{ unix\_shell}
\end{Highlighting}
\end{Shaded}

Has anything changed? How to list the contents of the folder again?

HINT (CLICK TO EXPAND)

\begin{quote}
ls
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

And now let's enter the \texttt{unix\_shell} folder:

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{cd}\NormalTok{ unix\_shell}
\end{Highlighting}
\end{Shaded}

Did it work? Where are we now?

HINT

\begin{quote}
pwd
\end{quote}

\subsection{Creating a new file}\label{creating-a-new-file}

Let's create a new file called \texttt{myfile.txt} by launching the text editor \texttt{nano}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{nano}\NormalTok{ myfile.txt}
\end{Highlighting}
\end{Shaded}

Now inside the nano screen:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Write some text
\item
  Exit the ``writing mode'' with ctrl+x
  nano
\item
  To save the file, type \textbf{y} and hit ``Enter''
\item
  Confirm the name of the file and hit ``Enter''
\end{enumerate}

List the contents of the folder. Can you see the file we have just created?

\subsection{Copying, renaming, moving and deleting files}\label{copying-renaming-moving-and-deleting-files}

First let's create a new folder called \texttt{myfolder}. Do you remember how to do this?

HINT

\begin{quote}
mkdir myfolder
\end{quote}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

And now let's make a copy of \texttt{myfile.txt}. Here, the command \texttt{cp} expects two arguments, and the order of these arguments matter. The first is the name of the file we want to copy, and the second is the name of the new file:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cp}\NormalTok{ myfile.txt newfile.txt}
\end{Highlighting}
\end{Shaded}

List the contents of the folder. Do you see the new file there?

Now let's say we want to copy a file and put it inside a folder. In this case, we give the name of the folder as the second argument to \texttt{cp}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cp}\NormalTok{ myfile.txt myfolder }

\CommentTok{\# while typing myfold.. try using the TAB to predict the name of the folder!}

\FunctionTok{cp}\NormalTok{ myfile.txt myfolder/  }\CommentTok{\# it will recognise it is a directory and add the / at the end.}
\end{Highlighting}
\end{Shaded}

List the contents of \texttt{myfolder}. Is \texttt{myfile.txt} there?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ls}\NormalTok{ myfolder}
\end{Highlighting}
\end{Shaded}

We can also copy the file to another folder and give it a different name, like this:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cp}\NormalTok{ myfile.txt myfolder/copy\_of\_myfile.txt}
\end{Highlighting}
\end{Shaded}

List the contents of \texttt{myfolder} again. Do you see two files there?

Instead of copying, we can move files around with the command \texttt{mv}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mv}\NormalTok{ newfile.txt myfolder}
\end{Highlighting}
\end{Shaded}

Let's list the contents of the folders. Where did \texttt{newfile.txt} go?

We can also use the command \texttt{mv} to rename files:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mv}\NormalTok{ myfile.txt myfile\_renamed.txt}
\end{Highlighting}
\end{Shaded}

List the contents of the folder again. What happened to \texttt{myfile.txt}?

Now, let's say we want to move things from inside \texttt{myfolder} to the current directory. Can you see what the dot (\texttt{.}) is doing in the command below? Let's try:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mv}\NormalTok{ myfolder/newfile.txt .}
\end{Highlighting}
\end{Shaded}

Let's list the contents of the folders. The file \texttt{newfile.txt} was inside \texttt{myfolder} before, where is it now?

The same operation can be done in a different way. In the commands below, can you see what the two dots (\texttt{.}) are doing? Let's try:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First we go inside the folder}
\BuiltInTok{cd}\NormalTok{ myfolder}

\CommentTok{\# Then we move the file one level up}
\FunctionTok{mv}\NormalTok{ myfile.txt ..}

\CommentTok{\# And then we go back one level}
\BuiltInTok{cd}\NormalTok{ ..}
\end{Highlighting}
\end{Shaded}

Let's list the contents of the folders. The file \texttt{myfile.txt} was inside \texttt{myfolder} before, where is it now?

To remove files :

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{ newfile.txt}
\end{Highlighting}
\end{Shaded}

Let's list the contents of the folder. What happened to \texttt{newfile.txt}?

And now let's delete \texttt{myfolder}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm}\NormalTok{ myfolder}
\end{Highlighting}
\end{Shaded}

It didn't work did it? An error message came up, what does it mean?

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{rm:}\NormalTok{ cannot remove ‘myfolder’: Is a directory}
\end{Highlighting}
\end{Shaded}

To delete a folder we have to modify the command further by adding the flag (\texttt{-r}). Flags are used to pass additional options to the commands:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rm} \AttributeTok{{-}r}\NormalTok{ myfolder}
\end{Highlighting}
\end{Shaded}

Let's list the contents of the folder. What happened to \texttt{myfolder}?

\begin{quote}
{[}!warning{]}
\textbf{In Bash, If you remove the wrong file/directory, it is gone forever!! (no recycle bin!)}
\textbf{aka BE CAREFUL!!}
\end{quote}

\chapter{16s Analysis}\label{s-analysis}

In this tutorial we are going to see/use different commands and tools to perform the 16s analysis on long reads NanoPore. However, the practical analysis will cover only some of these steps as data has been prepared in advance due to their computation and time consuming limits.

\textbf{This guide has been created with the purpose of a practical crush course and it is not intended as a complete reference but rather as a beginners pipeline to analyze NanoPore generated data.}

\section{Commands and features that we will use in our practice}\label{commands-and-features-that-we-will-use-in-our-practice}

\subsection{\texorpdfstring{\texttt{touch}}{touch}}\label{touch}

Create a new empty file.

Example: \texttt{touch\ prova.txt}

\subsection{\texorpdfstring{\texttt{echo}}{echo}}\label{echo}

The echo command is a built-in Linux feature that prints out arguments as the standard output. echo is commonly used \emph{to display text strings or command results as messages}.

Example: \texttt{echo\ "Hello\ World"}

\subsection{\texorpdfstring{\texttt{cat}}{cat}}\label{cat}

Concatenate or print the contents of a file

Example: \texttt{cat\ prova.txt}

\subsection{\texorpdfstring{\texttt{\$}}{\$}}\label{section}

Append \texttt{\$} to the variable name to access the variable value.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\VariableTok{var}\OperatorTok{=}\StringTok{"Hello World"}
\BuiltInTok{echo} \VariableTok{$var}
\end{Highlighting}
\end{Shaded}

Output:

\begin{quote}
Hello World
\end{quote}

\subsection{\texorpdfstring{\texttt{chmod}}{chmod}}\label{chmod}

Change the permissions of a file or directory and make it executable.

\begin{itemize}
\tightlist
\item
  use the ``chmod +x'' command on a system file to give permission to all users to execute it.
\item
  use the ``chmod u+x'' for made the file executable for your user.
\end{itemize}

Example: \texttt{chmod\ u+x\ s01\_filtering.sh}

\subsection{\texorpdfstring{\texttt{basename}}{basename}}\label{basename}

It removes the path from a file string, providing only its filename and trailing suffix from given file names.

Example:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{basename}\NormalTok{ /path/to/filename.txt}
\end{Highlighting}
\end{Shaded}

Output:

\begin{quote}
filename.txt
\end{quote}

\subsection{Create a shell scripts}\label{create-a-shell-scripts}

Sometime you don't need to run a command at a time, we can pre-think, organize series of actions (a program) that you can then execute within Bash.

For example we can write a shell script that runs a series of commands and we can run the script from the terminal to execute all the steps that we have integrated in the script.

For example, lets assume that we want to visualize the first four reads from a FASTQ and redirect to a file. For this task we are going to create an empty file and write in it the following text:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\FunctionTok{cat}\NormalTok{ /SERVER/16s\_data/mysample.FASTQ }\KeywordTok{|} \FunctionTok{head} \AttributeTok{{-}n}\NormalTok{ 4 }\OperatorTok{\textgreater{}}\NormalTok{ first\_read.fastq}

\VariableTok{var}\OperatorTok{=}\StringTok{"Hello World"}
\BuiltInTok{echo} \VariableTok{$var}
\end{Highlighting}
\end{Shaded}

Now we give the `executable' permission to our script in order to be executed:

\texttt{chmod\ u+x\ myscript.sh}

Now we execute our script:

\texttt{./myscript.sh}

\begin{itemize}
\tightlist
\item
  The first row must be \texttt{\#!/bin/bash} to allows the shell to interpret your code with bash
\item
  The symbol \texttt{\textbar{}} is the PIPE, it lets you connect actions: the output of a command is the input of the next command
\item
  The command \texttt{head} allows to print a specified number of rows from an input.
\item
  Sometime different actions cannot be linked with a PIPE, in this case we use to write the series of actions in each line, as we did in the last two rows of our scripts.
\end{itemize}

\section{Package Manager}\label{package-manager}

\subsection{Conda}\label{conda}

Conda is a powerful command line tool for package and environment management that runs on Windows, macOS, and Linux.

\url{https://conda.io/projects/conda/en/latest/user-guide/getting-started.html}

Within conda, you can create, export, list, remove, and update environments that have different versions of Python and/or packages installed in them. \emph{Switching or moving between environments is called activating the environment}. You can also share an environment file.

\subsection{Mamba (Recommended)}\label{mamba-recommended}

Mamba is a reimplementation of the conda package manager in C++, so it is faster and more convenient due to its faster dependencies solving.

\url{https://mamba.readthedocs.io/en/latest/user_guide/mamba.html}

\subsubsection{Creating a conda/mamba env}\label{creating-a-condamamba-env}

To create an environment:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{conda}\NormalTok{ create }\AttributeTok{{-}n}\NormalTok{ myenv}
\end{Highlighting}
\end{Shaded}

To activate a created environment:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{conda}\NormalTok{ activate myenv}
\end{Highlighting}
\end{Shaded}

\subsubsection{Installing tools}\label{installing-tools}

Most of the bioinformatics packages can be searched in Bioconda at this link \url{https://bioconda.github.io}, but also in \texttt{conda-forge} channel and then we can install them by executing

\begin{verbatim}
mamba install -c bioconda -c conda-forge nanofilt
\end{verbatim}

For our practical analysis, conda environments have already been created.

The following environment were created:

\begin{itemize}
\tightlist
\item
  \texttt{mamba\ activate\ /home/irsa/miniconda3/envs/ONTpp}
\item
  \texttt{mamba\ activate\ /home/irsa/miniconda3/envs/emu}
\end{itemize}

\section{Base Calling}\label{base-calling}

Base calling is the process of translating the electronic raw signal of the sequencer into bases, i.e., ATCG and converting the raw files (FAST5) to a FASTQ files (human-readable), which contains the nucleotide sequences of the reads.

Raw data are huge in terms of storage, and since basecalling is computationally and time demanding, the fastq files are already provided.

However, to perform this step we suggest to use one of the two following tools:

\subsection{Guppy}\label{guppy}

\url{https://community.nanoporetech.com/docs/prepare/library_prep_protocols/Guppy-protocol/v/gpb_2003_v1_revax_14dec2018/guppy-software-overview}

Guppy usage:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{guppy\_basecaller} \DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}num\_callers}\NormalTok{ 4 }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}cpu\_threads\_per\_caller}\NormalTok{ 64 }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}input\_path} \DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}save\_path} \DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}flowcell}\NormalTok{ FLO{-}MIN106 }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}kit}\NormalTok{ SQK{-}RBK004s}
\end{Highlighting}
\end{Shaded}

As we can see from the command line this tool requires the flowcell model and eventually barcoding kit information.

\subsection{Dorado}\label{dorado}

Recently released by Nanopore, Dorado is a high-performance, easy-to-use, open source basecaller for Oxford Nanopore reads, with the options of super, high and low, accuracy.

\url{https://github.com/nanoporetech/dorado}

First download the flowcell model kit (You need to know which flowcell was used):

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{dorado}\NormalTok{ download }\AttributeTok{{-}{-}model}\NormalTok{ dna\_r10.4.1\_e8.2\_400bps\_hac@v4.1.0}
\end{Highlighting}
\end{Shaded}

Dorado usage:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{dorado}\NormalTok{ basecaller }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}b}\NormalTok{ 36 }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}device}\NormalTok{ cpu }\DataTypeTok{\textbackslash{}}
  \AttributeTok{{-}{-}emit{-}fastq}
  \ExtensionTok{mysample.FAST5}
\end{Highlighting}
\end{Shaded}

\section{Filtering and Trimming}\label{filtering-and-trimming}

The fastq file containing the 16S sequence need to be filtered based on quality and/or read length, and optional trimmed after passing filter

\subsection{NanoFilt}\label{nanofilt}

NanoFilt - filtering and trimming of long read sequencing data

\url{https://github.com/wdecoster/nanofilt}

\emph{Requirement}

To execute this tool, you need to activate the conda environment

\texttt{mamba\ activate\ /home/irsa/miniconda3/envs/ONTpp}

\textbf{STEP TIPS:}

\begin{itemize}
\tightlist
\item
  Your input data are available in the following path: \texttt{/SERVER/16s\_data/}
\item
  Your task should be to use NanoFilt on each fastq file, using the following options:

  \begin{itemize}
  \tightlist
  \item
    \texttt{-\/-length\ LENGTH} Filter on a minimum read length
  \item
    \texttt{-\/-maxlength\ MAXLENGTH} Filter on a maximum read length
  \item
    \texttt{-\/-quality\ QUALITY} Filter on a minimum average read quality score
  \end{itemize}
\item
  Create the folder for your output files (to use in your script)
\item
  To perform this step you should create a script (Recommended name: \texttt{s01\_nanofilt.sh}), and give it permission to be executed: \texttt{chmod\ u+x\ s01\_nanofilt.sh}
\item
  Execute your script as follow: \texttt{./s01\_nanofilt.sh}
\item
  Look at the results
\end{itemize}

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s01\_nanofilt.sh}

\texttt{touch\ s01\_nanofilt.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ /SERVER/16s\_data/}\PreprocessorTok{*}\NormalTok{fastq}
\ControlFlowTok{do}
    \VariableTok{f}\OperatorTok{=}\VariableTok{$(}\FunctionTok{basename} \StringTok{"}\VariableTok{$i}\StringTok{"}\NormalTok{ .fastq}\VariableTok{)}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$f}\StringTok{"}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$i}\StringTok{"}
    \FunctionTok{cat} \VariableTok{$i} \KeywordTok{|} \ExtensionTok{NanoFilt} \AttributeTok{{-}q}\NormalTok{ 9 }\AttributeTok{{-}l}\NormalTok{ 1200 }\AttributeTok{{-}{-}maxlength}\NormalTok{ 1800 }\OperatorTok{\textgreater{}}\NormalTok{ /home/irsa/analisi\_16s/output\_s01/}\StringTok{"}\VariableTok{$f}\StringTok{"}\NormalTok{{-}nf.fastq}
\ControlFlowTok{done}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_16s/output_s01/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s01\_nanofilt.sh}

Execute it:
\texttt{./s01\_nanofilt.sh}

\section{Subsetting}\label{subsetting}

We are going to reduce the number of reads in order to use less resources for our practical analysis. \textbf{It is important to note that this step is not part of a common pipeline}.

\subsection{BBMAP Tools}\label{bbmap-tools}

BBMap - short read aligner for DNA/RNAseq, and other bioinformatic tools, including BBMap.

\url{https://github.com/BioInfoTools/BBMap}

From this step, we use a script provided by BBMAP tools collection, called: \texttt{reformat.sh}, which reformats reads to change ASCII quality encoding, interleaving, file format, or compression format.

\emph{Requirement}

To execute this tool, you need to activate the conda environment:

\texttt{mamba\ activate\ /home/irsa/miniconda3/envs/ONTpp}

\textbf{STEP TIPS:}

\begin{itemize}
\tightlist
\item
  Your input data should be available from the output folder of the previous step
\item
  Your task should be to use \texttt{reformat.sh} on \textbf{each output files obtained from the previous step}, using the following options:

  \begin{itemize}
  \tightlist
  \item
    \texttt{in=\textless{}file\textgreater{}} Input file
  \item
    \texttt{out=\textless{}outfile\textgreater{}} Ouput file
  \item
    \texttt{samplereadstarget=10000} Exact number of OUTPUT reads (or pairs) desired.
  \end{itemize}
\item
  Create the folder for your output files (to use in your script)
\item
  To perform this step you should create a script (Recommended name: \texttt{s02\_subsampling.sh}), and give it permission to be executed: \texttt{chmod\ u+x\ s02\_subsampling.sh}
\item
  Execute your script as follow: \texttt{./s02\_subsampling.sh}
\item
  Look at the results
\end{itemize}

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s02\_subsampling.sh}

\texttt{touch\ s02\_subsampling.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\CommentTok{\# Create output directory for this script}
\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ /home/irsa/analisi\_16s/output\_s02/}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ /home/irsa/analisi\_16s/output\_s01/}\PreprocessorTok{*}\NormalTok{{-}nf.fastq}
\ControlFlowTok{do}
    \VariableTok{f}\OperatorTok{=}\VariableTok{$(}\FunctionTok{basename} \StringTok{"}\VariableTok{$i}\StringTok{"} \AttributeTok{{-}nf.fastq}\VariableTok{)}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$f}\StringTok{"}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$i}\StringTok{"}
    \ExtensionTok{reformat.sh}\NormalTok{ in=}\StringTok{"}\VariableTok{$i}\StringTok{"}\NormalTok{ out=/home/irsa/analisi\_16s/output\_s02/}\StringTok{"}\VariableTok{$f}\StringTok{"}\NormalTok{{-}ss{-}nf.fastq samplereadstarget=10000}
\ControlFlowTok{done}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_16s/output_s02/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s02\_subsampling.sh}

\section{Taxonomic Assignment}\label{taxonomic-assignment}

Last step, the sequences are compared to a reference database for taxonomic assignment and a relative abundance estimator for 16S genomic sequences.

\subsection{EMU}\label{emu}

Emu - species-level taxonomic abundance for full-length 16S reads.

This tool use a method optimized for error-prone full-length reads. However, it can be used for short-reads.

\url{https://github.com/treangenlab/emu}

To perform this annotation, we need a reference database that contains all the taxonomic information, which was already been downloaded in the following path: \texttt{/SERVER/emu\_database}

\emph{Requirement}

To execute this tool, you need to activate the conda environment:

\texttt{mamba\ activate\ /home/irsa/miniconda3/envs/emu}

\textbf{STEP TIPS:}

\begin{itemize}
\tightlist
\item
  Your input data should be available from the previous step
\item
  Your task should be to use \texttt{emu\ abundance} on \textbf{each output files obtained from the previous step}, using the following options:

  \begin{itemize}
  \tightlist
  \item
    \texttt{-\/-type\ map-ont} denote sequencer {[}short-read:sr, Pac-Bio:map-pb, ONT:map-ont{]}
  \item
    \texttt{-\/-keep-counts} include estimated read counts for each species in output
  \item
    \texttt{-\/-output-dir\ \textless{}output\_dir\textgreater{}} directory for output results (to be created in advance)
  \item
    \texttt{-\/-output-basename\ \textless{}basename\_files\textgreater{}} basename of all output files saved in output-dir; default utilizes basename from input file(s)
  \end{itemize}
\item
  Create the folder for your output files (to use in your script)
\item
  To perform this step you should create a script (Recommended name: \texttt{s03\_abundance.sh}), and give it permission to be executed: \texttt{chmod\ u+x\ s03\_abundance.sh}

  \begin{itemize}
  \tightlist
  \item
    Specify the path of the EMU database with the following line as an action: \texttt{export\ EMU\_DATABASE\_DIR=/SERVER/emu\_database}
  \item
    Last line of your script, should be an action that performs the command \texttt{emu\ combine-outputs} to create a single table containing all Emu output relative abundances in a single directory. Note this function will select all the .tsv files in the provided directory that contain `rel-abundance' in the filename. Use the following options in your \texttt{emu\ combine-outputs} command:

    \begin{itemize}
    \tightlist
    \item
      \texttt{-\/-counts\ output} estimated counts rather than relative abundance percentage in combined table. Only includes Emu relative abundance outputs that already have `estimated counts'
    \item
      \texttt{tax\_id} to get results for the most specific taxa level
    \end{itemize}
  \end{itemize}
\item
  Execute your script as follow: \texttt{./s03\_abundance.sh}
\item
  Look at the results
\end{itemize}

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s03\_abundance.sh}

\texttt{touch\ s03\_abundance.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\CommentTok{\# mamba activate /home/irsa/miniconda3/envs/emu}

\BuiltInTok{export} \VariableTok{EMU\_DATABASE\_DIR}\OperatorTok{=}\NormalTok{/SERVER/emu\_database}

\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ /home/irsa/analisi\_16s/output\_s02/}\PreprocessorTok{*}\NormalTok{{-}ss{-}nf.fastq}
\ControlFlowTok{do}
    \VariableTok{f}\OperatorTok{=}\VariableTok{$(}\FunctionTok{basename} \StringTok{"}\VariableTok{$i}\StringTok{"} \AttributeTok{{-}ss{-}nf.fastq}\VariableTok{)}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$f}\StringTok{"}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$i}\StringTok{"}
    \ExtensionTok{emu}\NormalTok{ abundance }\StringTok{"}\VariableTok{$i}\StringTok{"} \AttributeTok{{-}{-}type}\NormalTok{ map{-}ont }\AttributeTok{{-}{-}output{-}basename} \StringTok{"}\VariableTok{$f}\StringTok{"} \AttributeTok{{-}{-}keep{-}counts} \AttributeTok{{-}{-}output{-}dir}\NormalTok{ /home/irsa/analisi\_16s/output\_s03/ }\AttributeTok{{-}{-}threads}\NormalTok{ 4}
\ControlFlowTok{done}


\ExtensionTok{emu}\NormalTok{ combine{-}outputs }\AttributeTok{{-}{-}counts}\NormalTok{ /home/irsa/analisi\_16s/output\_s03/ tax\_id}

\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_16s/output_s03/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s03\_abundance.sh}

\chapter{Metagenomics}\label{metagenomics}

The metagenomics sequence are produced using a shotgun approach in which each all the gene present inside the samples were sequenced. This sequencing not only extends taxonomic resolution to the species- or strain-level but also provides potential functional information

\section{Reads Quality Check}\label{reads-quality-check}

After the basecalling, on the fastq file the ``quality check'' of the sequence can be performed using stats.sh, a tool inc
luded in BBMap/BBTools

\subsection{\texorpdfstring{BBMap / \texttt{stats.sh}}{BBMap / stats.sh}}\label{bbmap-stats.sh}

\texttt{stats.sh} - Generates basic assembly statistics such as scaffold count, N50, L50, GC content, gap percent, etc. Works with fasta and fastq only (gzipped is fine).

\url{https://github.com/BioInfoTools/BBMap/blob/master/sh/stats.sh}

\section{Assembly}\label{assembly}

One of the most important step for the metagenomic analysis is the Assembly, in which the reads were compared, aligned and overlapped in order to create longer sequenced called ``CONTIGS''.

\subsection{Flye (Metaflye)}\label{flye-metaflye}

\textbf{Setup Conda Env}

\begin{verbatim}
mamba create -n flye -c conda-forge -c bioconda flye
\end{verbatim}

Flye is a de novo assembler for single molecule sequencing reads using repeat graphs as core data structure. Compared to de Bruijn graphs (which require exact k-mer matches), repeat graphs are built using approximate sequence matches.

\url{https://github.com/fenderglass/Flye}

Options used

\begin{itemize}
\tightlist
\item
  \texttt{-\/-nano-raw\ ONT} regular reads
\item
  \texttt{-\/-meta} enables the mode for metagenome/uneven coverage assembly
\item
  \texttt{-\/-out-dir\ \ \ \ \textless{}outputdir\textgreater{}} Output directory
\end{itemize}

\section{Read mapping}\label{read-mapping}

To quantify the coverage, we map the original input reads to the contig

\subsection{Minimap2}\label{minimap2}

A versatile pairwise aligner for genomic and spliced nucleotide sequences, used for evaluate the coverage of the original reads on each previously created contig using pairwise alignment.

A report and two charts are generated with complementary information, showing a summary of the DNA-Seq Alignment results.

This page contains information about the reference genome sequences, the input FASTQ files, and a results overview.

The last section is divided into several subsections: globals, paired information, ACTG content, coverage, mapping quality, insert size, mismatches, and indels.

Minimap2 rates an alignment by the score of the max-scoring sub-segment, excluding introns, and marks the best alignment as primary in SAM.

Sequence Alignment Map (SAM) is a text-based format originally for storing biological sequences aligned to a reference sequence.
Practically, SAM is a TAB-delimited text format consisting of a header section and an alignment section.
Header lines start with `@', while alignment lines do not.

\url{https://github.com/lh3/minimap2}

Example command line

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{minimap2} \AttributeTok{{-}ax}\NormalTok{ map{-}ont ref.fa ont{-}reads.fq }\OperatorTok{\textgreater{}}\NormalTok{ aln.sam}
\end{Highlighting}
\end{Shaded}

Options:
- \texttt{map-ont} Align noisy long reads of \textasciitilde10\% error rate to a reference genome. This is the default mode

\subsection{samtools}\label{samtools}

Samtools is a package for reading/writing/editing/indexing/viewing SAM/BAM/CRAM format.

A BAM file (*.bam) is a compressed binary version (BGZF format) of a SAM file that is used to represent aligned sequences. This file can be created starting from a SAM (using \texttt{samtools}) file in order to reduce its size.

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{samtools}\NormalTok{ sort aln.sam }\AttributeTok{{-}o}\NormalTok{ aln.bam}
\end{Highlighting}
\end{Shaded}

\section{Binning}\label{binning}

In metagenomics, binning is the process of grouping reads or contigs and assigning them to individual genome, called ``MAGs'' (Metagenome Assembled Genomes).

\subsection{SemiBin2}\label{semibin2}

\textbf{Setup Conda Env}

\begin{verbatim}
mamba create -n semibin -c conda-forge -c bioconda semibin
\end{verbatim}

SemiBin is a command line tool for metagenomic binning with semi-supervised siamese neural network using additional information from reference genomes and contigs themselves.
It supports single sample, co-assembly, and multi-samples binning modes.

\url{https://github.com/BigDataBiology/SemiBin}

3 Options are available for this tool:

\begin{itemize}
\tightlist
\item
  \texttt{single\_easy\_bin}: Running with single-sample binning
\item
  \texttt{multi\_easy\_bin}: Running with multi-sample binning
\item
  \texttt{co-assembly}: samples are co-assembled first (as if the pool of samples were a single sample) and then bins are constructed from this pool of co-assembled contigs.
\end{itemize}

You will need the following inputs:

\begin{itemize}
\tightlist
\item
  A contig file (contig.fa in the example below)
\item
  BAM file(s) from mapping short reads to the contigs, sorted (mapped\_reads.sorted.bam in the example below)
\end{itemize}

The \texttt{single\_easy\_bin} command can be used to produce results in a single step

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{SemiBin2}\NormalTok{ single\_easy\_bin }\AttributeTok{{-}{-}sequencing{-}type}\OperatorTok{=}\NormalTok{long\_read }\AttributeTok{{-}{-}input{-}fasta}\NormalTok{ assembly.fasta }\AttributeTok{{-}{-}input{-}bam}\NormalTok{ aln.bam }\AttributeTok{{-}{-}output}\NormalTok{ output\_folder}
\end{Highlighting}
\end{Shaded}

Alternatively, you can train a new model for that sample, by not passing in the \texttt{-\/-environment} flag.

This is the fastest option and should work the best if you have metagenomes from one of our prebuilt habitats (alternatively, you can use the global ``habitat'' which combines all of them).

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{SemiBin2}\NormalTok{ single\_easy\_bin }\AttributeTok{{-}{-}sequencing{-}type}\OperatorTok{=}\NormalTok{long\_read }\AttributeTok{{-}{-}environment}\NormalTok{ human\_gut }\AttributeTok{{-}{-}input{-}fasta}\NormalTok{ assembly.fasta }\AttributeTok{{-}{-}input{-}bam}\NormalTok{ aln.bam }\AttributeTok{{-}{-}output}\NormalTok{ output\_folder }
\end{Highlighting}
\end{Shaded}

\section{MAGs Quality Check}\label{mags-quality-check}

As well as the original reads and contigs, also MAGs can be checked to extract the ones that can be considered High Quality.

\subsection{CheckM2}\label{checkm2}

CheckM2 - Rapid assessment of genome bin quality using machine learning

\url{https://github.com/chklovski/CheckM2}

CheckM2 has universally trained machine learning models it applies regardless of taxonomic lineage to predict the completeness and contamination of genomic bins.
Completeness is the percentage of the mapped genome that were covered by each mag.
Contamination is the inclusion of foreign sequences on the mags

The strain heterogeneity (SH) index indicates the proportion of the contamination that appears to be from the same or similar strains (as determined with an AAI threshold).

In order to extract the completeness and contamination for each Mags, You will also need to download and install the external DIAMOND database that CheckM2 relies on for rapid annotation.

\textbf{Setup Conda Env and install CheckM2 Database}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mamba}\NormalTok{ create }\AttributeTok{{-}n}\NormalTok{ checkm2 }\AttributeTok{{-}c}\NormalTok{ bioconda }\AttributeTok{{-}c}\NormalTok{ conda{-}forge checkm2}
\ExtensionTok{mamba}\NormalTok{ activate checkm2}

\ExtensionTok{pip}\NormalTok{ install CheckM2}

\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ /path/to/checkm2\_database}
\ExtensionTok{checkm2}\NormalTok{ database }\AttributeTok{{-}{-}download} \AttributeTok{{-}{-}path}\NormalTok{ /path/to/checkm2\_database/}
\end{Highlighting}
\end{Shaded}

As we can see in the following command, the database path can also be set by using the environmental variable.

The main use of CheckM2 is to predict the completeness and contamination of metagenome-assembled genomes (MAGs)

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{export} \VariableTok{CHECKM2DB}\OperatorTok{=}\StringTok{"/path/to/checkm2\_database/"}

\ExtensionTok{checkm2}\NormalTok{ predict }\AttributeTok{{-}{-}threads}\NormalTok{ 64 }\AttributeTok{{-}{-}input}\NormalTok{ /path/output/output\_bins/ }\AttributeTok{{-}{-}output{-}directory}\NormalTok{ output\_folder}
\end{Highlighting}
\end{Shaded}

\section{Taxonomic Classification}\label{taxonomic-classification}

\subsection{GTDB-Tk}\label{gtdb-tk}

\subsubsection{Setup Conda Env}\label{setup-conda-env}

\begin{verbatim}
mamba create -n gtdbtk -c conda-forge -c bioconda gtdbtk=2.3.2
\end{verbatim}

GTDB-tk - assigning taxonomic classifications

\url{https://github.com/Ecogenomics/GTDBTk}

GTDB-Tk is the software toolkit used for assigning objective taxonomic classifications to bacterial and archaeal genomes based on the Genome Database Taxonomy (GTDB).
It is designed to work with recent advances that allow hundreds or thousands of metagenome-assembled genomes (MAGs) to be obtained directly from environmental samples.

GTDB-Tk requires an external database that needs to be downloaded and unarchived:

\url{https://ecogenomics.github.io/GTDBTk/installing/index.html\#gtdb-tk-reference-data}

To perform the taxonomic classification, we use the workflow function \texttt{classify\_wf} which consists (internally) of four steps: \emph{ani\_screen}, \emph{identify}, \emph{align}, and \emph{classify}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{gtdbtk}\NormalTok{ classify\_wf }\AttributeTok{{-}{-}genome\_dir}\NormalTok{ selected\_genomes/ }\AttributeTok{{-}{-}out\_dir}\NormalTok{ classify\_wf\_out }\AttributeTok{{-}{-}extension}\NormalTok{ fa }\AttributeTok{{-}{-}force} \AttributeTok{{-}{-}cpus}\NormalTok{ 32 }\AttributeTok{{-}{-}skip\_ani\_screen} \AttributeTok{{-}{-}pplacer\_cpus}\NormalTok{ 32}
\end{Highlighting}
\end{Shaded}

Options used:

\begin{itemize}
\tightlist
\item
  \texttt{-\/-genome\_dir\ \textless{}directory\textgreater{}} directory containing genome files in FASTA format\\
\item
  \texttt{-\/-out\_dir\ \textless{}directory\textgreater{}} directory to output files
\item
  \texttt{-\/-extension\ fa} extension of files to process, gz = gzipped
\item
  \texttt{-\/-force} continue processing if an error occurs on a single genome
\item
  \texttt{-\/-skip\_ani\_screen} Skip the ani\_screening step to classify genomes using mash and FastANI
\item
  \texttt{-\/-pplacer\_cpus\ 32} number of CPUs to use during pplacer placement
\end{itemize}

List of output files:

\begin{itemize}
\tightlist
\item
  summary.tsv: Classifications for bacterial and archaeal genomes (see the GTDB-Tk documentation for details). Here we will find:

  \begin{itemize}
  \tightlist
  \item
    \emph{fastani\_reference}: indicates the accession number of the reference genome (species) to which a user genome was assigned based on ANI and AF. ANI values are only calculated when a query genome is placed within a defined genus and are evaluated for all reference genomes in that genus.
  \item
    \emph{fastani\_reference\_radius}: indicates the species-specific ANI circumscription radius of the reference genomes used to determine if a query genome should be classified to the same species as the reference.
    \url{https://ecogenomics.github.io/GTDBTk/files/summary.tsv.html}
  \item
    \emph{fastani\_af}: indicates the alignment fraction (AF) between the query and above reference genome.
  \item
    \emph{closest\_placement\_reference}: indicates the accession number of the reference genome when a genome is placed on a terminal branch.
  \item
    \emph{classification\_method}: indicates the rule used to classify the genome.
  \end{itemize}
\item
  \emph{classify.tree.gz}: Reference tree in Newick format containing query genomes placed with pplacer.
\item
  \emph{markers\_summary.tsv}: A summary of unique, duplicated, and missing markers within the 120 bacterial marker set, or the 122 archaeal marker set for each submitted genome.
\item
  \emph{msa.fasta.gz}: FASTA file containing MSA of submitted and reference genomes.
\item
  \emph{filtered.tsv}: A list of genomes with an insufficient number of amino acids in MSA.
\item
  \emph{log}: Log files.
\item
  \emph{failed\_genomes.tsv}: A list of genomes for which the GTDB-Tk analysis failed, e.g.~because Prodigal could not detect any genes.
\item
  \emph{gtdbtk\_summary.tsv}: A summary table of the GTDB-Tk classification results for all bins
\end{itemize}

The taxonomic classification of each bacterial and archaeal genome is contained in the \texttt{{[}prefix{]}.{[}domain{]}.summary.tsv} output files.

A strain identifier is used as a placeholder for the genus name when there is no existing genus name and no binomially named representative genome.
This placeholder genus name is generally derived from the oldest representative genome within the lineage and formed from NCBI organism name or NCBI infraspecific/strain ID.

\section{Functional Annotation}\label{functional-annotation}

\subsection{Anvi'o}\label{anvio}

For the final and detailed analysis of the MAGs (both from short and long reads) several specific tool were developed in the last years (i.e.~is Anvi'o).

Anvi'o is a comprehensive platform that brings together many aspects of today's cutting-edge computational strategies of data-enabled microbiology, including genomics, metagenomics, metatranscriptomics, pangenomics, metapangenomics, phylogenomics, and microbial population genetics in an integrated and easy-to-use fashion through extensive interactive visualization capabilities.

\url{https://anvio.org/}

\url{https://github.com/merenlab/anvio}

\textbf{Setup anvio and download databases}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mamba}\NormalTok{ create }\AttributeTok{{-}y} \AttributeTok{{-}{-}name}\NormalTok{ anvio{-}8 python=3.10}
\ExtensionTok{mamba}\NormalTok{ activate anvio{-}8}
\ExtensionTok{mamba}\NormalTok{ install }\AttributeTok{{-}y} \AttributeTok{{-}c}\NormalTok{ conda{-}forge }\AttributeTok{{-}c}\NormalTok{ bioconda python=3.10 }\DataTypeTok{\textbackslash{}}
\NormalTok{        sqlite prodigal idba mcl muscle=3.8.1551 famsa hmmer diamond }\DataTypeTok{\textbackslash{}}
\NormalTok{        blast megahit spades bowtie2 bwa graphviz }\StringTok{"samtools\textgreater{}=1.9"} \DataTypeTok{\textbackslash{}}
\NormalTok{        trimal iqtree trnascan{-}se fasttree vmatch r{-}base r{-}tidyverse }\DataTypeTok{\textbackslash{}}
\NormalTok{        r{-}optparse r{-}stringi r{-}magrittr bioconductor{-}qvalue meme ghostscript}
        
\ExtensionTok{mamba}\NormalTok{ install }\AttributeTok{{-}y} \AttributeTok{{-}c}\NormalTok{ bioconda fastani}

\ExtensionTok{curl} \AttributeTok{{-}L}\NormalTok{ https://github.com/merenlab/anvio/releases/download/v8/anvio{-}8.tar.gz }\DataTypeTok{\textbackslash{}}
        \AttributeTok{{-}{-}output}\NormalTok{ anvio{-}8.tar.gz}
       
\FunctionTok{sudo}\NormalTok{ apt install build{-}essential}
\ExtensionTok{pip}\NormalTok{ install anvio{-}8.tar.gz}


\FunctionTok{mkdir} \AttributeTok{{-}p}\NormalTok{ /SERVER/anvio{-}db/pfam /SERVER/anvio{-}db/kegg /SERVER/anvio{-}db/cazy /SERVER/anvio{-}db/scg       }

\ExtensionTok{anvi{-}setup{-}kegg{-}data} \AttributeTok{{-}{-}mode}\NormalTok{ KOfam }\AttributeTok{{-}{-}only{-}download} \AttributeTok{{-}{-}kegg{-}data{-}dir}\NormalTok{ /SERVER/anvio{-}db/kegg/}
\ExtensionTok{anvi{-}setup{-}pfams} \AttributeTok{{-}{-}pfam{-}data{-}dir}\NormalTok{ /SERVER/anvio{-}db/pfam/}
\ExtensionTok{anvi{-}setup{-}cazymes} \AttributeTok{{-}{-}cazyme{-}data{-}dir}\NormalTok{ /SERVER/anvio{-}db/cazy/}
\ExtensionTok{anvi{-}setup{-}scg{-}taxonomy} \AttributeTok{{-}{-}scgs{-}taxonomy{-}data{-}dir}\NormalTok{ /SERVER/anvio{-}db/scg/ }\AttributeTok{{-}{-}reset}
\end{Highlighting}
\end{Shaded}

the following workflow is useful for converting a bunch of genomes into an anvi'o-compatible format. It generates contigs databases from each input FASTA file, and subsequently runs a variety of annotation programs of your choice to populate these databases with some useful information for your downstream work (i.e.~functions, single-copy-core genes, taxonomy, etc).

To start things going with this workflow, first ask anvi'o to give you a default workflow-config file for the contigs workflow:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{anvi{-}run{-}workflow} \AttributeTok{{-}w}\NormalTok{ contigs }\AttributeTok{{-}{-}get{-}default{-}config}\NormalTok{ contigs.json}
\end{Highlighting}
\end{Shaded}

Used options:
- \texttt{-w\ contigs} select the different type of ``workflow (i.e.~contig, metagenome \ldots)
- \texttt{-\/-get-default-config\ contigs.json} generate a default config file (.json) for a given workflow

\url{https://anvio.org/help/main/workflows/contigs/}

Here we create a \texttt{file\_list.tsv}

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{echo} \AttributeTok{{-}e} \StringTok{"name\textbackslash{}tpath"} \OperatorTok{\textgreater{}}\NormalTok{ file\_list.tsv }\KeywordTok{\&\&} \FunctionTok{find}\NormalTok{ path/to/selected\_genomes }\AttributeTok{{-}type}\NormalTok{ f }\AttributeTok{{-}exec}\NormalTok{ sh }\AttributeTok{{-}c} \StringTok{\textquotesingle{}echo {-}e "$(basename "\{\}" .fa)\textbackslash{}t\{\}"\textquotesingle{}} \DataTypeTok{\textbackslash{};} \OperatorTok{\textgreater{}\textgreater{}}\NormalTok{ file\_list.tsv}
\end{Highlighting}
\end{Shaded}

If everything looks alright, you can run this workflow the following way from the same folder of file\_list.tsv:

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{anvi{-}run{-}workflow} \AttributeTok{{-}w}\NormalTok{ contigs }\AttributeTok{{-}c}\NormalTok{ contigs.json }\AttributeTok{{-}{-}additional{-}params} \AttributeTok{{-}{-}jobs}\NormalTok{ 3}
\end{Highlighting}
\end{Shaded}

Finally, perform the annotation using one of the pre-loaded database

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ 02\_CONTIGS/}\PreprocessorTok{*}\NormalTok{.db}\KeywordTok{;} \CommentTok{\# 02\_CONTIGS viene generata da anvi{-}run{-}workflow}
\ControlFlowTok{do}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$i}\StringTok{"}\KeywordTok{;}
    \ExtensionTok{anvi{-}run{-}cazymes} \AttributeTok{{-}c} \VariableTok{$i} \AttributeTok{{-}{-}cazyme{-}data{-}dir}\NormalTok{ path/to/CAZYdb/}\KeywordTok{;}
\ControlFlowTok{done}
\end{Highlighting}
\end{Shaded}

and export the annotation

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in}\NormalTok{ 02\_CONTIGS/}\PreprocessorTok{*}\NormalTok{.db}\KeywordTok{;} \CommentTok{\# 02\_CONTIGS viene generata da anvi{-}run{-}workflow}
\ControlFlowTok{do}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$i}\StringTok{"}\KeywordTok{;}
    \ExtensionTok{anvi{-}export{-}functions} \AttributeTok{{-}c} \VariableTok{$i}
\ControlFlowTok{done}
\end{Highlighting}
\end{Shaded}

\chapter{Our Metagenomic practice}\label{our-metagenomic-practice}

In our practice we will cover the functional annotation on metagenomics data, both on assembly based and MAGs based. Due to resources and time limits we will try to run Prodigal, HMMer and Quast.

For the assembly-based analysis, we have the assembly fasta file located in the following path: \texttt{/SERVER/mg\_data/Assembly\_metaflye/assembly.fasta}

\section{ORF Prediction}\label{orf-prediction}

Fast, reliable protein-coding gene prediction for prokaryotic genomes.

\url{https://github.com/hyattpd/Prodigal}

\subsection{Prodigal}\label{prodigal}

\textbf{Setup the conda env}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mamba}\NormalTok{ create }\AttributeTok{{-}n}\NormalTok{ prodigal }\AttributeTok{{-}c}\NormalTok{ bioconda }\AttributeTok{{-}c}\NormalTok{ conda{-}forge prodigal}
\end{Highlighting}
\end{Shaded}

Tips:

\begin{itemize}
\tightlist
\item
  Input: Prodigal run using a fasta file, for example the one represented the assembly
\item
  Output: You should obtains a GFF file and an Aminoacidic Fasta file of the predicted orfs
\end{itemize}

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s01\_prodigal.sh}

\texttt{touch\ s01\_prodigal.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\VariableTok{assembly}\OperatorTok{=}\StringTok{"/SERVER/mg\_data/Assembly\_metaflye/assembly.fasta"}


\VariableTok{outfolder}\OperatorTok{=}\StringTok{"output\_s01"}

\FunctionTok{mkdir} \AttributeTok{{-}p} \VariableTok{$outfolder}

\ExtensionTok{prodigal} \AttributeTok{{-}i} \VariableTok{$\{assembly\}} \DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}o} \VariableTok{$\{outfolder\}}\NormalTok{/genes.gff }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}a} \VariableTok{$\{outfolder\}}\NormalTok{/protein\_translations.faa }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}f}\NormalTok{ gff }\DataTypeTok{\textbackslash{}}
    \AttributeTok{{-}p}\NormalTok{ meta}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_MG/output_s01/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s01\_prodigal.sh}

Execute it:
\texttt{./s01\_prodigal.sh}

\section{Hidden Markov Model}\label{hidden-markov-model}

HMMER is a software package that provides tools for making probabilistic models of protein and DNA sequence domain families -- called profile hidden Markov models, profile HMMs, or just profiles.

HMMER is used for searching sequence databases for sequence homologs, and for making sequence alignments. It implements methods using probabilistic models called profile hidden Markov models (profile HMMs).

\url{https://github.com/EBI-Metagenomics/hmmer3}

\subsection{hmmer}\label{hmmer}

\textbf{Setup the conda env}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mamba}\NormalTok{ create }\AttributeTok{{-}n}\NormalTok{ hmmer }\AttributeTok{{-}c}\NormalTok{ bioconda }\AttributeTok{{-}c}\NormalTok{ conda{-}forge hmmer}
\end{Highlighting}
\end{Shaded}

\subsubsection{Split PFAM files}\label{split-pfam-files}

Pfam is a comprehensive collection of protein domains and families, represented as multiple sequence alignments and as profile hidden Markov models.

Download the file \texttt{Pfam-A.hmm.gz} from the PFAM FTP Server: \url{https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/}

\paragraph*{\texorpdfstring{\textbf{Step 0}}{Step 0}}\label{step-0}
\addcontentsline{toc}{paragraph}{\textbf{Step 0}}

De-Compress the file \texttt{Pfam-A.hmm.gz}. How will you do it?
TIPS:

\begin{itemize}
\tightlist
\item
  Search on google
\end{itemize}

\textbf{{[}SPOILER{]}} - Scripts that we will use

\texttt{gzip\ -d\ Pfam-A.hmm.gz}

\paragraph*{\texorpdfstring{\textbf{Step 1}}{Step 1}}\label{step-1}
\addcontentsline{toc}{paragraph}{\textbf{Step 1}}

Extract the name of the models in the PFAM file \textbf{(Advanced Task)}

\textbf{{[}SPOILER{]}} - Scripts that we will use

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{grep} \StringTok{"\^{}NAME"}\NormalTok{ Pfam{-}A.hmm }\KeywordTok{|} \FunctionTok{awk} \StringTok{\textquotesingle{}\{print $2\}\textquotesingle{}} \OperatorTok{\textgreater{}}\NormalTok{ all\_names.txt}
\end{Highlighting}
\end{Shaded}

\paragraph*{\texorpdfstring{\textbf{Step 2}}{Step 2}}\label{step-2}
\addcontentsline{toc}{paragraph}{\textbf{Step 2}}

Using the retrieved names, extract the corresponding models into multiple files.

Command to use: \texttt{hmmfetch} from the hmmer tools

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s02\_splitPFAM.sh}

\texttt{touch\ s02\_splitPFAM.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\VariableTok{outfolder}\OperatorTok{=}\StringTok{"output\_s02"}

\ControlFlowTok{while} \BuiltInTok{read} \VariableTok{name}
\ControlFlowTok{do}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$name}\StringTok{"}
    \ExtensionTok{hmmfetch}\NormalTok{ Pfam{-}A.hmm }\VariableTok{$name} \OperatorTok{\textgreater{}} \StringTok{"}\VariableTok{$\{outfolder\}}\StringTok{/}\VariableTok{$name}\StringTok{.hmm"}
\ControlFlowTok{done} \OperatorTok{\textless{}}\NormalTok{ 500\_names.txt}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_MG/output_s02/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s02\_splitPFAM.sh}

Execute it:
\texttt{./s02\_splitPFAM.sh}

\subsubsection{\texorpdfstring{\texttt{hmmsearch}}{hmmsearch}}\label{hmmsearch}

Now execute \texttt{hmmsearch} to the retrieved ORFs to annotate them based on the extracted models.

If you are working on the CNR system, use only 1 cpu.

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s03\_hmmsearch.sh}

\texttt{touch\ s03\_hmmsearch.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}


\VariableTok{outfolder}\OperatorTok{=}\StringTok{"output\_s03"}

\ControlFlowTok{while} \BuiltInTok{read} \VariableTok{name}\KeywordTok{;} \ControlFlowTok{do}
    \BuiltInTok{echo} \StringTok{"}\VariableTok{$name}\StringTok{"}

    \VariableTok{model\_folder}\OperatorTok{=}\StringTok{"}\VariableTok{$\{outfolder\}}\StringTok{/}\VariableTok{$\{name\}}\StringTok{"}
    \FunctionTok{mkdir} \AttributeTok{{-}p} \VariableTok{$\{model\_folder\}}

    \VariableTok{model}\OperatorTok{=}\StringTok{"output\_s02/}\VariableTok{$\{name\}}\StringTok{.hmm"}

    \ExtensionTok{hmmsearch} \AttributeTok{{-}{-}tblout} \VariableTok{$\{model\_folder\}}\NormalTok{/table.out }\AttributeTok{{-}o} \VariableTok{$\{model\_folder\}}\NormalTok{/align.out }\AttributeTok{{-}E}\NormalTok{ 0.000001 }\AttributeTok{{-}{-}cpu}\NormalTok{ 1 }\AttributeTok{{-}{-}notextw} \VariableTok{$\{model\}}\NormalTok{ output\_s01/protein\_translations.faa}

\ControlFlowTok{done} \OperatorTok{\textless{}}\NormalTok{ 500\_names.txt}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_MG/output_s03/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s03\_hmmsearch.sh}

Execute it:
\texttt{./s03\_hmmsearch.sh}

\section{Assembly Quality Check}\label{assembly-quality-check}

\subsection{Quast}\label{quast}

The QUAST package works both with and without reference genomes. However, it is much more informative if at least a close reference genome is provided along with the assemblies. The tool accepts multiple assemblies, thus is suitable for comparison.

\url{https://github.com/ablab/quast}

\textbf{Setup the conda env}

\begin{Shaded}
\begin{Highlighting}[]
\ExtensionTok{mamba}\NormalTok{ create }\AttributeTok{{-}n}\NormalTok{ quast }\AttributeTok{{-}c}\NormalTok{ bioconda }\AttributeTok{{-}c}\NormalTok{ conda{-}forge quast}
\end{Highlighting}
\end{Shaded}

\textbf{{[}SPOILER{]}} - Scripts that we will use

We create an empty file called \texttt{s04\_quast.sh}

\texttt{touch\ s04\_quast.sh}

We can write our actions in the scripts as follows:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#!/bin/bash}

\VariableTok{outfolder}\OperatorTok{=}\StringTok{"output\_s04"}


\ExtensionTok{quast} \AttributeTok{{-}{-}labels}\NormalTok{ flye }\AttributeTok{{-}{-}contig{-}thresholds}\NormalTok{ 0,1000,10000,100000,1000000 }\AttributeTok{{-}{-}threads}\NormalTok{ 2 }\AttributeTok{{-}o} \VariableTok{$\{outfolder\}}\NormalTok{ /SERVER/mg\_data/Assembly\_metaflye/assembly.fasta}
\end{Highlighting}
\end{Shaded}

Create output directory for this script (Change \texttt{irsa} with your \texttt{utenteX} name)

\begin{verbatim}
mkdir -p /home/irsa/analisi_MG/output_s04/
\end{verbatim}

Change its permission:
\texttt{chmod\ u+x\ s04\_quast.sh}

Execute it:
\texttt{./s04\_quast.sh}

What if you use \texttt{metaquast}?

\textbf{{[}SPOILER{]}} - Scripts that we will use

MetaQUAST the extension for metagenomic datasets, it evaluates and compares metagenome assemblies based on alignments to close references. It is based on QUAST genome quality assessment tool, but addresses features specific for metagenome datasets.

\section{Web Tools Annotations}\label{web-tools-annotations}

\begin{itemize}
\tightlist
\item
  KOFAM Koala \url{https://www.genome.jp/tools/kofamkoala/}
\item
  EGGNOG \url{http://eggnog-mapper.embl.de}
\item
  DBcan \url{https://bcb.unl.edu/dbCAN2/blast.php}
\end{itemize}

\section{Functional Annotation - MAGs based}\label{functional-annotation---mags-based}

If you have finished, try to run the same analysis on each MAGs located in:
\texttt{/SERVER/mg\_data/mg/genomi\_per\_annotazione}

\end{document}
